{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import matplotlib\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import firescipy as fsp\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "## ! Use the 'requirements.txt' to create a virtual Python environment ! ##\n",
    "###########################################################################\n",
    "\n",
    "# Package Versions\n",
    "# ----------------\n",
    "# Python version: 3.13.3 (tags/v3.13.3:6280bb5, Apr  8 2025, 14:47:33) [MSC v.1943 64 bit (AMD64)]\n",
    "# Python path: F:\\PhD\\BESKID\\Pyrolysis_BESKID_Paper\\BESKID_Paper_venv\\venv_BESKID_Paper\\Scripts\\python.exe\n",
    "# Numpy version: 2.3.2\n",
    "# SciPy version: 1.16.1\n",
    "# Pandas version: 2.3.1\n",
    "# FireSciPy version: 0.0.5\n",
    "# Matplotlib version: 3.10.5\n",
    "# RegEx version: 2.2.1\n",
    "\n",
    "\n",
    "print('Package Versions')\n",
    "print('----------------')\n",
    "print('Python version: {}'.format(sys.version))\n",
    "print('Python path: {}'.format(sys.executable))\n",
    "print('Numpy version: {}'.format(np.__version__))\n",
    "print('SciPy version: {}'.format(sp.__version__))\n",
    "print('Pandas version: {}'.format(pd.__version__))\n",
    "print('FireSciPy version: {}'.format(fsp.__version__))\n",
    "print('Matplotlib version: {}'.format(matplotlib.__version__))\n",
    "print('RegEx version: {}'.format(re.__version__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General information.\n",
    "\n",
    "exp_tubs_root = os.path.join(\"..\", \"Experiments\", \"TUBS\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Order of plot colors\n",
    "plt_colors = [\"tab:blue\", \"tab:orange\", \"tab:green\", \n",
    "              \"tab:red\", \"tab:purple\", \"tab:brown\", \n",
    "              \"tab:pink\", \"tab:gray\", \"tab:olive\", \n",
    "              \"tab:cyan\"]\n",
    "\n",
    "# Basic plot settings\n",
    "plt.rcParams.update({\n",
    "    'axes.axisbelow': True,     # Keep grid behind plots\n",
    "    'figure.autolayout': True,  # Equivalent to calling tight_layout()\n",
    "    'axes.facecolor': 'white',  # Prevents transparent background\n",
    "    'grid.alpha': 0.6,          # Makes gridlines more readable\n",
    "})\n",
    "\n",
    "\n",
    "# Directory used to collect the output produced by this notebook.\n",
    "output_dir = \"AssessExperiments_Output\"\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "    print(\"* Output directory created.\")\n",
    "else:\n",
    "    print(\"* Output directory already exists.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Micro-Scale Experiments\n",
    "\n",
    "Focus on the STA and MCC experiments conducted by iBMB.\n",
    "- [DOI: 10.24355/dbbs.084-202508070641-0](https://doi.org/10.24355/dbbs.084-202508070641-0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store data\n",
    "tubs_microscale_data = dict()\n",
    "\n",
    "# Define regular expression (regex) patterns for different experiment types\n",
    "patterns = {\n",
    "#     \"microscale\": re.compile(r'(?P<setup>tga|mcc)_(?P<temp_program>isotherm|dynamic)_(?P<atmosphere>n2)_(iso|dyn?P<temp>\\d+(?:[-.]\\d+)?)_(?P<sample>piece|powder)_(?P<mass>\\d+(?:[-.]\\d+)?mg)_(?P<rep>\\d+(?:[-.]\\d+)?)?\\.(?:csv|txt)'),\n",
    "    \"microscale\": re.compile(\n",
    "        r'(?P<setup>tga|mcc)_'\n",
    "        r'(?P<temp_program>isotherm|dynamic)_'\n",
    "#         r'(?P<atmosphere>n2)_'\n",
    "#         r'(?P<atmosphere>n2|n2high|n2low)(?P<purge_flow>\\d+(?:[-.]\\d+)?)_'\n",
    "#         r'(?P<atmosphere>n2(?:high|low))(?P<purge_flow>\\d+(?:[.-]\\d+)?)?(?:_|$)'\n",
    "        r'(?P<atmosphere>n2(?:high|low)?)(?P<purge_flow>\\d+(?:[.-]\\d+)?)?(?:_|$)'\n",
    "        r'(?P<temp_prefix>iso|dyn)(?P<temp_number>\\d+(?:[-.]\\d+)?)_'\n",
    "        r'(?P<sample>piece|powder|powdertubs)_'\n",
    "        r'(?P<mass>\\d+(?:[-.]\\d+)?mg)_'\n",
    "        r'(?P<rep>r\\d+)\\.(?:csv|txt)',\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "# Keep track of processed files to make sure all are captured\n",
    "skipped_files = list()\n",
    "\n",
    "# Loop through experimental setups\n",
    "for exp_setup in os.listdir(exp_tubs_root):\n",
    "    exp_setup_path = os.path.join(exp_tubs_root, exp_setup) \n",
    "    if not os.path.isdir(exp_setup_path):\n",
    "        continue  # Skip non-directories\n",
    "\n",
    "    print(f\"* Processing {exp_setup} ...\")\n",
    "\n",
    "    # Loop through files in experimental setup directory\n",
    "    for file_label in os.listdir(exp_setup_path):\n",
    "        print(f\"  {file_label}\")\n",
    "        \n",
    "        file_info = None\n",
    "        matched_type = None\n",
    "\n",
    "        # Try matching against different regex patterns\n",
    "        for exp_type, pattern in patterns.items():\n",
    "            match = pattern.match(file_label)\n",
    "            if match:\n",
    "                file_info = match.groupdict()\n",
    "                matched_type = exp_type\n",
    "                break  # Stop at the first match\n",
    "        \n",
    "        # If no valid format was found, skip the file\n",
    "        if not file_info:\n",
    "            skipped_files.append(file_label)\n",
    "            continue\n",
    "        \n",
    "        # If no proper repetition label is provided, show message\n",
    "        if not file_info.get(\"rep\"):\n",
    "            print(f\"** File label '{file_label}' is missing a repetiton number --> file skipped!\")\n",
    "            skipped_files.append(file_label)\n",
    "            continue\n",
    "        \n",
    "        # Extract metadata\n",
    "        exp_setup = file_info.get(\"setup\", \"tga\")  # Default to \"tga\" if missing\n",
    "        rep_label = f\"Rep_{file_info['rep'][1:]}\"\n",
    "\n",
    "        if matched_type == \"microscale\":\n",
    "            atmosphere = f\"{file_info['atmosphere']}\"\n",
    "            purge_flow = f\"{file_info['purge_flow']}\"\n",
    "            \n",
    "            if purge_flow == \"None\":\n",
    "                atmo_label = f\"{file_info['atmosphere']}\"\n",
    "            else:\n",
    "                atmo_label = f\"{file_info['atmosphere']}{file_info['purge_flow']}\"\n",
    "            print(\"***\", atmo_label)\n",
    "#             purge_flow = f\"{file_info['purge_flow']}\"\n",
    "#             print(purge_flow)\n",
    "            temp_program = file_info[\"temp_program\"]\n",
    "            sample_type = file_info[\"sample\"]\n",
    "            sample_mass = file_info[\"mass\"]\n",
    "            unit_map = {\"iso\": \"C\", \"dyn\": \"Kmin\"}\n",
    "            temp_label = f'{file_info[\"temp_number\"]}{unit_map[file_info[\"temp_prefix\"]]}'            \n",
    "            keys = [exp_setup, atmo_label, sample_type, sample_mass, temp_program, temp_label, rep_label]\n",
    "\n",
    "        # Read the CSV\n",
    "        exp_path = os.path.join(exp_setup_path, file_label)\n",
    "        exp_df = pd.read_csv(exp_path, header=0, skiprows=[1], \n",
    "                             delimiter=\"\\t\", encoding='cp1252')\n",
    "        \n",
    "#         print(exp_df.head(2))\n",
    "\n",
    "        # Store in nested dictionary\n",
    "        fsp.utils.store_in_nested_dict(tubs_microscale_data, exp_df, keys)\n",
    "\n",
    "        print(f\"  Loaded {file_label} -> {keys}\")\n",
    "        \n",
    "    print()\n",
    "\n",
    "# Display skipped files\n",
    "if skipped_files:\n",
    "    print(\"* The following files were skipped:\\n\" + \"\\n\".join(skipped_files))\n",
    "\n",
    "print(\"\\n* Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# Store Data from Experiments and Kinetics Computations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fzj_powder_masses = [\"1mg\", \"2mg\", \"3mg\", \"6mg\", \"12mg\"]\n",
    "fzj_powder = tubs_microscale_data[\"tga\"]['n2']['powder']\n",
    "\n",
    "fzj_powder[\"1mg\"][\"dynamic\"][\"10Kmin\"][\"Rep_1\"].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desired sample properties\n",
    "sample_masses=[\"1mg\", \"2mg\", \"3mg\"]\n",
    "fzj_powder = tubs_microscale_data[\"tga\"]['n2']['powder']\n",
    "\n",
    "# Provide nominal temperature program\n",
    "hrs = {\n",
    "    \"5Kmin\": [5.0, \"K/min\"],\n",
    "    \"10Kmin\": [10, \"K/min\"],\n",
    "    \"20Kmin\": [20, \"K/min\"],\n",
    "    \"30Kmin\": [30, \"K/min\"],\n",
    "    \"60Kmin\": [60, \"K/min\"]\n",
    "}\n",
    "\n",
    "\n",
    "# Initialise kinetics data collection\n",
    "BESKID_data = {\n",
    "    \"dynamic\": dict(),\n",
    "    \"isotherm\": dict()}\n",
    "\n",
    "\n",
    "for sample_mass in sample_masses:\n",
    "    # Initialise investigation.\n",
    "    investigation = fsp.pyrolysis.kinetics.initialize_investigation_skeleton(\n",
    "        material=f\"PMMA DE 6mm ({sample_mass}), BESKID\",  # Sample material\n",
    "        investigator=\"iBMB (TUBS)\",  # Conducted experiments\n",
    "        instrument=\"TGA/DSC 3+, Mettler Toledo\", \n",
    "        date=\"Stardate: 42.69\", \n",
    "        notes=\"Constant heating rates, sample mass 1mg\",\n",
    "        signal={\"name\": \"Mass\", \"unit\": \"mg\"}\n",
    "    )\n",
    "    \n",
    "    # Get constant heating rate data (dynamic)\n",
    "    dyn_exp = fzj_powder[sample_mass][\"dynamic\"]\n",
    "    for hr_label in hrs:\n",
    "        \n",
    "        # Go over the repetitions\n",
    "        for rep_label in dyn_exp[hr_label]:\n",
    "            # Get the data set\n",
    "            rep_data = dyn_exp[hr_label][rep_label]\n",
    "            # Adjust temperatures to Kelvin\n",
    "            rep_data['ts'] = rep_data['ts'] + 273.15\n",
    "            rep_data['tr'] = rep_data['tr'] + 273.15\n",
    "            \n",
    "            # Add raw experiment data set to collection.\n",
    "            fsp.pyrolysis.kinetics.add_constant_heating_rate_tga(\n",
    "                database=investigation, \n",
    "                condition=hr_label, \n",
    "                repetition=rep_label, \n",
    "                raw_data=rep_data, \n",
    "                data_type=\"integral\", \n",
    "                set_value=hrs[hr_label])\n",
    "    \n",
    "    \n",
    "        # Column header mapping - adjust to your file structure!\n",
    "        # This is the standard, i.e. column_mapping=None\n",
    "        column_labels = {\n",
    "            'time': 't', \n",
    "            'temp': 'ts', \n",
    "            'signal': 'weight'}\n",
    "        \n",
    "        # Combine repetitions\n",
    "        fsp.pyrolysis.kinetics.combine_repetitions(\n",
    "            database=investigation, \n",
    "            condition=hr_label, \n",
    "            column_mapping=column_labels)\n",
    "        \n",
    "    # Compute the conversions of the combined data\n",
    "    fsp.pyrolysis.kinetics.compute_conversion(\n",
    "        database=investigation,\n",
    "        condition=\"all\",  # Can also compute for individual temperature programs, e.g. \"5Kmin\"\n",
    "        setup=\"constant_heating_rate\")\n",
    "\n",
    "    # Compute the conversion fractions, necessary for KAS method\n",
    "    # Default conversion levels.\n",
    "    # from 0.05 to 0.95, in 0.025 steps\n",
    "    conversion_levels = np.linspace(0.01, 0.99, 99)  # Δα = 1.0\n",
    "\n",
    "    fsp.pyrolysis.kinetics.compute_conversion_levels(\n",
    "        database=investigation, \n",
    "        desired_levels=conversion_levels,\n",
    "        setup=\"constant_heating_rate\", \n",
    "        condition=\"all\")\n",
    "\n",
    "\n",
    "    # Compute estimates for activation energy and pre-exponenital factor\n",
    "    # using Kissinger–Akahira–Sunose with Starink improvement\n",
    "    fsp.pyrolysis.kinetics.compute_Ea_KAS(database=investigation)\n",
    "\n",
    "    # Collect results.\n",
    "    BESKID_data[\"dynamic\"][sample_mass] = investigation\n",
    "\n",
    "\n",
    "# Check results\n",
    "Ea_results_KAS_BESKID = BESKID_data[\"dynamic\"][\"1mg\"][\"experiments\"][\"TGA\"][\"Ea_results_KAS\"]\n",
    "Ea_results_KAS_BESKID.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write combined repetitions to disk (average, std)\n",
    "sample_masses = [\"1mg\", \"2mg\", \"3mg\"]\n",
    "\n",
    "for sample_mass in sample_masses:\n",
    "    # sample_mass = '1mg'\n",
    "    constant_heating_rate = BESKID_data[\"dynamic\"][sample_mass][\"experiments\"][\"TGA\"][\"constant_heating_rate\"]\n",
    "    \n",
    "    for hr_label in list(constant_heating_rate):\n",
    "        # hr_label = \"10Kmin\"\n",
    "        combined_df = constant_heating_rate[hr_label][\"combined\"]\n",
    "        \n",
    "        file_name = os.path.join(output_dir, f\"TGA_{sample_mass}_{hr_label}.csv\")\n",
    "        combined_df.to_csv(file_name, sep=',', encoding='utf-8', index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise Ea over alpha\n",
    "institute = \"TUBS\"\n",
    "sample_mass = \"1mg\"\n",
    "\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "for mass_id, sample_mass in enumerate(sample_masses):\n",
    "    # Get the Ea and convert to kJ/mol.\n",
    "    Ea_results_KAS = BESKID_data[\"dynamic\"][sample_mass][\"experiments\"][\"TGA\"][\"Ea_results_KAS\"]\n",
    "    y_data = Ea_results_KAS[\"Ea\"]/1000\n",
    "\n",
    "    # Plot the Ea against conversion.\n",
    "    start = 1  # Skip the 0.05 because of being outlier\n",
    "    stop = None\n",
    "    ax1.scatter(Ea_results_KAS[\"Conversion\"][start:stop],\n",
    "                y_data[start:stop],\n",
    "#                 marker='o', s=17,\n",
    "                marker=\".\", s=42,\n",
    "                facecolors='none',\n",
    "                edgecolors=plt_colors[mass_id],\n",
    "                label=f\"Exp.: {institute}, {sample_mass}, KAS\")\n",
    "\n",
    "\n",
    "# Shaded areas to indicate first/last 5 % (typically excluded)\n",
    "x_min = -0.025\n",
    "x_max = 1.025\n",
    "ax1.axvspan(x_min, 0.05, color='gray', alpha=0.3, label=\"5%\")\n",
    "ax1.axvspan(0.95, x_max, color='gray', alpha=0.3)\n",
    "\n",
    "\n",
    "# Plot meta data.\n",
    "# plt.title(f\"Activation Energy (KAS)\")\n",
    "plt.xlabel(\"Conversion ($\\\\alpha$) / -\")\n",
    "plt.ylabel(\"Activation Energy (E$_a$) / kJ/mol\")\n",
    "\n",
    "plt.xlim(left=-0.025, right=1.025)\n",
    "plt.ylim(bottom=160, top=240)\n",
    "\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.grid()\n",
    "\n",
    "\n",
    "# Save image.\n",
    "plot_label = f\"{institute}_Ea_Estimate_KAS.png\"\n",
    "plot_path = os.path.join(output_dir, plot_label)\n",
    "plt.savefig(plot_path, dpi=320, bbox_inches='tight', facecolor='w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv_BESKID_Paper)",
   "language": "python",
   "name": "venv_beskid_paper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
